{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification and denoising\n",
    "\n",
    "### The CIFAR-10 dataset\n",
    "We will work on the [**CIFAR-10 dataset**](https://www.cs.toronto.edu/~kriz/cifar.html) collected by Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton from the University of Toronto.  This dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. Each image is a 3-channel colour images of 32x32 pixels in size. There are 50000 training images and 10000 test images. \n",
    "\n",
    "\t\t\t\n",
    "### Data loading and manipulation\n",
    "\n",
    " **Download** both the training and test data of the CIFAR-10 dataset, e.g., by following the [pytorch CIFAR10 tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "**Add random noise** to all training and test data to generate noisy dataset, e.g., by `torch.randn()`, with a scaling  factor `scale`, e.g., original image `+ scale * torch.randn()`, and **normalise/standardise** the pixel values to the **original range**, e.g.,  using `np.clip()`. You may choose any `scale` value between 0.2 and 0.5. \n",
    "\n",
    "**Note: Before generating the random noise, MUST set the random seed for reproducibility, e.g., using `torch.manual_seed()`. This seed needs to be used for all remaining code if there is randomness, for reproducibility.**\n",
    "\n",
    "**Extract a subset** with only two classes: **Cat** and **Dog** and name it starting with **CatDog**.        \n",
    "\n",
    "Show 10 pairs of original and noisy images of cats and 10 pairs of original and noisy images of dogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below is various methods to implement explanations above.\n",
    "\n",
    "# Method 1\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(140206229)\n",
    "scale = 0.2\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + scale * torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "\n",
    "def get_relevant_indices(dataset, classes, target_classes):\n",
    "    indices = []\n",
    "    for i in range(len(dataset)):\n",
    "        # Check if the label is in the target classes\n",
    "        label_index = dataset[i][1] # ex: 3\n",
    "        label_class = classes[label_index] # ex: 'cat'\n",
    "        if label_class in target_classes:\n",
    "            indices.append(i)\n",
    "\n",
    "    return indices\n",
    "\n",
    "def normalize(data):\n",
    "    \"\"\"\n",
    "    Given a tensor containing 2 possible values, normalize this to 0/1\n",
    "\n",
    "    Args:\n",
    "        labels: a 1D tensor containing two possible scalar values\n",
    "    Returns:\n",
    "        A tensor normalize to 0/1 value\n",
    "    \"\"\"\n",
    "    max_val = torch.max(data)\n",
    "    min_val = torch.min(data)\n",
    "    norm_data = (data - min_val)/(max_val - min_val)\n",
    "\n",
    "    return norm_data\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "transform1 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    AddGaussianNoise(0., 1.)\n",
    "])\n",
    "\n",
    "# Download the data set\n",
    "original_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform1)\n",
    "\n",
    "original_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform1)\n",
    "\n",
    "# Put random noise, normalise will be done later using fuction above\n",
    "noised_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform2)\n",
    "\n",
    "noised_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform2)\n",
    "\n",
    "\n",
    "# Get the list of indices to sample from\n",
    "cat_dog_train_indices = get_relevant_indices(original_trainset,classes,[\"cat\", \"dog\"])\n",
    "cat_dog_test_indices = get_relevant_indices(original_testset, classes, [\"cat\", \"dog\"])\n",
    "\n",
    "cat_train_indices = get_relevant_indices(original_trainset,classes,[\"cat\"])\n",
    "cat_test_indices = get_relevant_indices(original_testset,classes,[\"cat\"])\n",
    "\n",
    "dog_train_indices = get_relevant_indices(original_trainset,classes,[\"dog\"])\n",
    "dog_test_indices = get_relevant_indices(original_testset,classes,[\"dog\"])\n",
    "\n",
    "\n",
    "\n",
    "cat_dog_train_sampler = SubsetRandomSampler(cat_dog_train_indices)\n",
    "dog_train_sampler = SubsetRandomSampler(dog_train_indices)\n",
    "cat_train_sampler = SubsetRandomSampler(cat_train_indices)\n",
    "\n",
    "cat_dog_test_sampler = SubsetRandomSampler(cat_dog_test_indices)\n",
    "dog_test_sampler = SubsetRandomSampler(dog_test_indices)\n",
    "cat_test_sampler = SubsetRandomSampler(cat_test_indices)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 10 pairs of original/noised cats and dogs\n",
    "\n",
    "original_dog_train_loader = torch.utils.data.DataLoader(original_trainset, batch_size=10,\n",
    "                                          num_workers=1, sampler=dog_train_sampler)\n",
    "noised_dog_train_loader = torch.utils.data.DataLoader(noised_trainset, batch_size=10,\n",
    "                                          num_workers=0, sampler=dog_train_sampler)\n",
    "\n",
    "original_cat_train_loader = torch.utils.data.DataLoader(original_trainset, batch_size=10,\n",
    "                                          num_workers=1, sampler=cat_train_sampler)\n",
    "noised_cat_train_loader = torch.utils.data.DataLoader(noised_trainset, batch_size=10,\n",
    "                                          num_workers=0, sampler=cat_train_sampler)\n",
    "\n",
    "\n",
    "    \n",
    "# Show images of dogs\n",
    "dataiter_dog1 = iter(original_dog_train_loader)\n",
    "images_dog1, labels_dog2 = dataiter_dog1.next()\n",
    "dataiter_dog2 = iter(noised_dog_train_loader)\n",
    "images_dog2, labels_dog2 = dataiter_dog2.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images_dog1))\n",
    "imshow(torchvision.utils.make_grid(images_dog2))\n",
    "\n",
    "\n",
    "# Show images of cats\n",
    "dataiter_cat1 = iter(original_cat_train_loader)\n",
    "images_cat1, labels_cat2 = dataiter_cat1.next()\n",
    "dataiter_cat2 = iter(noised_cat_train_loader)\n",
    "images_cat2, labels_cat2 = dataiter_cat2.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images_cat1))\n",
    "imshow(torchvision.utils.make_grid(images_cat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "\n",
    "# Download the data set and put random noise\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(140206229)\n",
    "\n",
    "scale = 0.2\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + scale * torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "########################################################################\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "# We transform them to Tensors of normalized range [-1, 1].\n",
    "transform1 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    AddGaussianNoise(0., 1.)\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform1)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform1)\n",
    "\n",
    "classes = {'plane':0, 'car':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a subset\n",
    "x_train = trainset.data\n",
    "x_test = testset.data\n",
    "y_train = trainset.targets\n",
    "y_test = testset.targets\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def get_class_i(x, y, i):\n",
    "    # Convert to a numpy array\n",
    "    y = np.array(y)\n",
    "    # Locate position of labels that equals to i\n",
    "    pos_i = np.argwhere(y == i)\n",
    "    # Convert the result into a 1-D list\n",
    "    pos_i = list(pos_i[:,0])\n",
    "    # Collect all data that match the desired label\n",
    "    x_i = [x[j] for j in pos_i]\n",
    "    \n",
    "    return x_i\n",
    "\n",
    "class DatasetMaker(Dataset):\n",
    "    def __init__(self, datasets, transformFunc = transform2):\n",
    "        self.datasets = datasets\n",
    "        self.lengths  = [len(d) for d in self.datasets]\n",
    "        self.transformFunc = transformFunc\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        class_label, index_wrt_class = self.index_of_which_bin(self.lengths, i)\n",
    "        img = self.datasets[class_label][index_wrt_class]\n",
    "        img = self.transformFunc(img)\n",
    "        return img, class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return sum(self.lengths)\n",
    "    \n",
    "    def index_of_which_bin(self, bin_sizes, absolute_index, verbose=False):\n",
    "        # Which class/bin does i fall into?\n",
    "        accum = np.add.accumulate(bin_sizes)\n",
    "        if verbose:\n",
    "            print(\"accum =\", accum)\n",
    "        bin_index  = len(np.argwhere(accum <= absolute_index))\n",
    "        if verbose:\n",
    "            print(\"class_label =\", bin_index)\n",
    "        # Which element of the fallent class/bin does i correspond to?\n",
    "        index_wrt_class = absolute_index - np.insert(accum, 0, 0)[bin_index]\n",
    "        if verbose:\n",
    "            print(\"index_wrt_class =\", index_wrt_class)\n",
    "\n",
    "        return bin_index, index_wrt_class\n",
    "\n",
    "# CatDog dataset    \n",
    "\n",
    "original_cat_dog_trainset = DatasetMaker([get_class_i(x_train, y_train, classes['cat']), \n",
    "                                 get_class_i(x_train, y_train, classes['dog'])],\n",
    "                                 transform1)\n",
    "original_cat_dog_testset  = DatasetMaker([get_class_i(x_test , y_test , classes['cat']),\n",
    "                                 get_class_i(x_test , y_test , classes['dog'])],\n",
    "                                 transform1)\n",
    "\n",
    "\n",
    "noised_cat_dog_trainset = DatasetMaker([get_class_i(x_train, y_train, classes['cat']), \n",
    "                                 get_class_i(x_train, y_train, classes['dog'])],\n",
    "                                 transform2)\n",
    "noised_cat_dog_testset  = DatasetMaker([get_class_i(x_test , y_test , classes['cat']),\n",
    "                                 get_class_i(x_test , y_test , classes['dog'])],\n",
    "                                 transform2)\n",
    "\n",
    "\n",
    "# 1Show 10 pairs of original/noised cat and dog\n",
    "# Cats dataset\n",
    "original_cat_trainset = DatasetMaker([get_class_i(x_train, y_train, classes['cat']), \n",
    "                                 get_class_i(x_train, y_train, classes['cat'])],\n",
    "                                 transform1)\n",
    "noised_cat_trainset = DatasetMaker([get_class_i(x_train, y_train, classes['cat']), \n",
    "                                 get_class_i(x_train, y_train, classes['cat'])],\n",
    "                                 transform2)\n",
    "\n",
    "original_cat_trainloader = torch.utils.data.DataLoader(original_cat_trainset, batch_size=10, \n",
    "                                               shuffle=True , num_workers=0)\n",
    "noised_cat_trainloader = torch.utils.data.DataLoader(noised_cat_trainset, batch_size=10, \n",
    "                                               shuffle=True , num_workers=0)\n",
    "\n",
    "# Dogs dataset\n",
    "original_dog_trainset = DatasetMaker([get_class_i(x_train, y_train, classes['dog']), \n",
    "                                 get_class_i(x_train, y_train, classes['dog'])],\n",
    "                                 transform1)\n",
    "noised_dog_trainset = DatasetMaker([get_class_i(x_train, y_train, classes['dog']), \n",
    "                                 get_class_i(x_train, y_train, classes['dog'])],\n",
    "                                 transform2)\n",
    "\n",
    "original_dog_trainloader = torch.utils.data.DataLoader(original_dog_trainset, batch_size=10, \n",
    "                                               shuffle=True , num_workers=0)\n",
    "noised_dog_trainloader = torch.utils.data.DataLoader(noised_dog_trainset, batch_size=10, \n",
    "                                               shuffle=True , num_workers=0)\n",
    "\n",
    "\n",
    "# Show images of cats\n",
    "dataiter_cat1 = iter(original_cat_trainloader)\n",
    "images_cat1, labels_cat1 = dataiter_cat1.next()\n",
    "\n",
    "dataiter_cat2 = iter(noised_cat_trainloader)\n",
    "images_cat2, labels_cat2 = dataiter_cat2.next()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(images_cat1))\n",
    "imshow(torchvision.utils.make_grid(images_cat2))\n",
    "\n",
    "# Show images of dogs\n",
    "dataiter_dog1 = iter(original_dog_trainloader)\n",
    "images_dog1, labels_dog1 = dataiter_dog1.next()\n",
    "\n",
    "dataiter_dog2 = iter(noised_dog_trainloader)\n",
    "images_dog2, labels_dog2 = dataiter_dog2.next()\n",
    "    \n",
    "imshow(torchvision.utils.make_grid(images_dog1))\n",
    "imshow(torchvision.utils.make_grid(images_dog2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method3 (recommended)\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from keras.layers.noise import GaussianNoise\n",
    "\n",
    "# Download the data set\n",
    "\n",
    "torch.manual_seed(140206229)\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('Traning data shape:', x_train.shape)\n",
    "print('Testing data shape:', x_test.shape)\n",
    "\n",
    "\n",
    "# Put random noise\n",
    "scale = 0.2\n",
    "\n",
    "x_train = (x_train-x_train.mean())/(x_train.max()-x_train.min())\n",
    "x_test = (x_test-x_test.mean())/(x_test.max()-x_test.min())\n",
    "x_train_noised = x_train + scale * np.random.normal(loc=0.0, scale=scale, size=x_train.shape)\n",
    "x_test_noised = x_test + scale * np.random.normal(loc=0.0, scale=scale, size=x_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# Extract a subset\n",
    "# Original\n",
    "x_train_cat = x_train[np.where(y_train==3)[0],:,:,:]\n",
    "x_train_dog = x_train[np.where(y_train==5)[0],:,:,:]\n",
    "x_train_cat_dog = np.concatenate((x_train_cat,x_train_dog), axis=0)\n",
    "\n",
    "y_train_cat = y_train[np.where(y_train==3)[0],:]\n",
    "y_train_dog = y_train[np.where(y_train==5)[0],:]\n",
    "y_train_cat_dog = np.concatenate((y_train_cat,y_train_dog), axis=0)\n",
    "\n",
    "x_test_cat = x_test[np.where(y_test==3)[0],:,:,:]\n",
    "x_test_dog = x_test[np.where(y_test==5)[0],:,:,:]\n",
    "x_test_cat_dog = np.concatenate((x_test_cat,x_test_dog), axis=0)\n",
    "\n",
    "y_test_cat = y_test[np.where(y_test==3)[0],:]\n",
    "y_test_dog = y_test[np.where(y_test==5)[0],:]\n",
    "y_test_cat_dog = np.concatenate((y_test_cat,y_test_dog), axis=0)\n",
    "\n",
    "# Noised\n",
    "\n",
    "x_train_cat_noised = x_train_noised[np.where(y_train==3)[0],:,:,:]\n",
    "x_train_dog_noised = x_train_noised[np.where(y_train==5)[0],:,:,:]\n",
    "x_train_cat_dog_noised = np.concatenate((x_train_cat_noised,x_train_dog_noised), axis=0)\n",
    "\n",
    "y_train_cat_noised = y_train[np.where(y_train==3)[0],:]\n",
    "y_train_dog_noised = y_train[np.where(y_train==5)[0],:]\n",
    "y_train_cat_dog_noised = np.concatenate((y_train_cat_noised,y_train_dog_noised), axis=0)\n",
    "\n",
    "x_test_cat_noised = x_test_noised[np.where(y_test==3)[0],:,:,:]\n",
    "x_test_dog_noised = x_test_noised[np.where(y_test==5)[0],:,:,:]\n",
    "x_test_cat_dog_noised = np.concatenate((x_test_cat_noised,x_test_dog_noised), axis=0)\n",
    "\n",
    "y_test_cat_noised = y_test[np.where(y_test==3)[0],:]\n",
    "y_test_dog_noised = y_test[np.where(y_test==5)[0],:]\n",
    "y_test_cat_dog_noised = np.concatenate((y_test_cat_noised,y_test_dog_noised), axis=0)\n",
    "\n",
    "# Show 10 pairs of original/noised cat and dog\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "\n",
    "def imshow(data_set):\n",
    "    fig = plt.figure(figsize=(5., 5.))\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 5),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 )\n",
    "    for ax, im in zip(grid, data_set):\n",
    "        ax.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x_train_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x_train_cat_noised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x_train_dog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x_train_dog_noised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction, binary classification, and evaluation\n",
    "\n",
    "This uses the **CatDog** subset **with no noise added**.\n",
    "\n",
    "#### Training\n",
    "\n",
    "Apply PCA on the training set to reduce the dimensionality. **At least seven** different values for the reduced dimensionality.\n",
    "\n",
    "**Eight** Naive Bayes classifiers: one on the original features (raw pixels), and seven on the seven different PCA features.\n",
    "\n",
    "#### Testing and evaluation\n",
    "The eight Naive Bayes classifiers explaned on the test set in terms of **classification accuracy** and **visualise** their performance using a bar graph.\n",
    "\n",
    "Plot the [ROC Curves](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) in true positive rates vs false positive rates for the eight Naive Bayes classifiers in **one figure** using eight different line/marker styles clearly labelled. \n",
    "\n",
    "Compute the [area under the ROC curve](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve) values for the eight Naive Bayes classifiers and visualise using a bar graph.\n",
    "\n",
    "**At least three** interesting observations from the evaluation results above described.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "\n",
    "# Reduce the dimension\n",
    "x_train_cat_dog_reshape = x_train_cat_dog.reshape(x_train_cat_dog.shape[0],3*32*32)\n",
    "x_test_cat_dog_reshape = x_test_cat_dog.reshape(x_test_cat_dog.shape[0],3*32*32)\n",
    "\n",
    "y_train_cat_dog_f = y_train_cat_dog.flatten()\n",
    "y_test_cat_dog_f = y_test_cat_dog.flatten()\n",
    "\n",
    "\n",
    "\"With wide range of number of components, can obtain wide range of results as well.\"\n",
    "no_components1 = 50\n",
    "no_components2 = 200\n",
    "no_components3 = 450\n",
    "no_components4 = 800\n",
    "no_components5 = 1050\n",
    "no_components6 = 1500\n",
    "no_components7 = 2000\n",
    "\n",
    "\n",
    "# Train eight Naive Bayes classifiers\n",
    "model = GaussianNB()\n",
    "\n",
    "# With original features\n",
    "model.fit(x_train_cat_dog_reshape, y_train_cat_dog_f)\n",
    "\n",
    "# With 7 pca features\n",
    "\n",
    "def PCA_x_xt(no_components):\n",
    "    pca = PCA(n_components=no_components, svd_solver='randomized', whiten=True)\n",
    "    \n",
    "    x_pca_2d = pca.fit_transform(x_train_cat_dog_reshape)\n",
    "    xt_pca_2d = pca.transform(x_test_cat_dog_reshape)\n",
    "    \n",
    "    model.fit(x_pca_2d, y_train_cat_dog_f)\n",
    "    \n",
    "    X_pred = model.predict(xt_pca_2d)\n",
    "    \n",
    "    return X_pred\n",
    "\n",
    "# Test and visualise\n",
    "\n",
    "# Naive Bayes with raw pixels\n",
    "X_pred1 = model.predict(x_test_cat_dog_reshape)\n",
    "\n",
    "pd_results = pd.DataFrame([\n",
    "        ['No PCA', metrics.accuracy_score(y_test_cat_dog_f, X_pred1)],\n",
    "        [no_components1, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components1))],\n",
    "        [no_components2, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components2))],\n",
    "        [no_components3, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components3))],\n",
    "        [no_components4, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components4))],\n",
    "        [no_components5, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components5))],\n",
    "        [no_components6, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components6))],\n",
    "        [no_components7, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components7))]\n",
    "    ], columns=['Number of PCA Components', 'Accuracy'])\n",
    "pd_results.plot(kind='barh', x='Number of PCA Components', y='Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC curve (label = dog)\n",
    "\n",
    "def roc_get_fp_tp(no_components):\n",
    "    pred = PCA_x_xt(no_components)\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test_cat_dog_f, pred, pos_label=5)\n",
    "    \n",
    "    return fpr, tpr\n",
    "\n",
    "fpr2, tpr2 = roc_get_fp_tp(no_components1)\n",
    "fpr3, tpr3 = roc_get_fp_tp(no_components2)\n",
    "fpr4, tpr4 = roc_get_fp_tp(no_components3)\n",
    "fpr5, tpr5 = roc_get_fp_tp(no_components4)\n",
    "fpr6, tpr6 = roc_get_fp_tp(no_components5)\n",
    "fpr7, tpr7 = roc_get_fp_tp(no_components6)\n",
    "fpr8, tpr8 = roc_get_fp_tp(no_components7)\n",
    "\n",
    "\n",
    "# For NB without PCA\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test_cat_dog_f, X_pred1, pos_label=5)\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(1, figsize=(12, 6))\n",
    "plt.plot(fpr, tpr, color='cyan', label='No PCA')\n",
    "plt.plot(fpr2, tpr2, color='blue', label='ROC curve pca:50')\n",
    "plt.plot(fpr3, tpr3, color='red', label='ROC curve pca:200')\n",
    "plt.plot(fpr4, tpr4, color='orange', label='ROC curve pca:450')\n",
    "plt.plot(fpr5, tpr5, color='black', label='ROC curve pca:800')\n",
    "plt.plot(fpr6, tpr6, color='yellow', label='ROC curve pca:1050')\n",
    "plt.plot(fpr7, tpr7, color='green', label='ROC curve pca:1500')\n",
    "plt.plot(fpr8, tpr8, color='magenta', label='ROC curve pca:2000')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate (1 - specificity)')\n",
    "plt.ylabel('True Positive Rate (sensitivity)')\n",
    "plt.title('ROC Curve for CIFAR10')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot AUC\n",
    "\n",
    "pd_results = pd.DataFrame([\n",
    "        ['No PCA', metrics.auc(fpr, tpr)],\n",
    "        [no_components1, metrics.auc(fpr2, tpr2)],\n",
    "        [no_components2, metrics.auc(fpr3, tpr3)],\n",
    "        [no_components3, metrics.auc(fpr4, tpr4)],\n",
    "        [no_components4, metrics.auc(fpr5, tpr5)],\n",
    "        [no_components5, metrics.auc(fpr6, tpr6)],\n",
    "        [no_components6, metrics.auc(fpr7, tpr7)],\n",
    "        [no_components7, metrics.auc(fpr8, tpr8)]\n",
    "    ], columns=['Number of PCA Components', 'AUC'])\n",
    "pd_results.plot(kind='barh', x='Number of PCA Components', y='AUC')\n",
    "\n",
    "# Observations\n",
    "\n",
    "# 1. The accuracy without applying PCA is still fairly high. This may tell applying PCA is not always \n",
    "# helpful. By itself, it can give good result and works well.\n",
    "\n",
    "# 2. Some of PCA applied showed lower accuracies than the one that's not. This may tell applying not all\n",
    "# ks are helpful, but only specific number. To find those good ks, it needs several attempts with different/wide range of k values\n",
    "\n",
    "# 3. Currently, the highest accuracy is from when k = 800 and the lowest is when k = 1500. Having too much ks is not always correct answer.\n",
    "#  The AUC is shows same trend as the accuracy score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy data and multiclass classification\n",
    "\n",
    "#### Noisy **CatDog** subset.\n",
    "\n",
    "Repeat process above on the noisy version of CatDog subset.\n",
    "\n",
    "#### Multiclass classification using the original CIFAR-10 dataset (all 10 classes)\n",
    "\n",
    "Apply PCA on the training set to reduce the dimensionality.\n",
    "\n",
    "Train nine classifers: **four Naive Bayes** classifiers(one on the original features, and three on the three different PCA features in 3b); **four Logistic Regression** classifiers (one on the original features, and three on the three different PCA features in 3b); and one **Convoluational Neural Network** as defined in the [pytorch CIFAR10 tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "Evalaute the nine classifiers on the test set. Summarised the **classification accuracy**, **total training time**, and **total test time** using three bar graphs.\n",
    "\n",
    "The confusion matrix for these nine classifiers shown\n",
    "\n",
    "Described **at least three** interesting observations from the evaluation results above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat above for noisy dataset\n",
    "\n",
    "# Reduce dimensions\n",
    "x_train_cat_dog_noised_reshape = x_train_cat_dog_noised.reshape(x_train_cat_dog_noised.shape[0],3*32*32)\n",
    "x_test_cat_dog_noised_reshape = x_test_cat_dog_noised.reshape(x_test_cat_dog_noised.shape[0],3*32*32)\n",
    "\n",
    "y_train_cat_dog_noised_f = y_train_cat_dog_noised.flatten()\n",
    "y_test_cat_do_noised_f = y_test_cat_dog_noised.flatten()\n",
    "\n",
    "no_components1 = 50\n",
    "no_components2 = 200\n",
    "no_components3 = 450\n",
    "no_components4 = 800\n",
    "no_components5 = 1050\n",
    "no_components6 = 1500\n",
    "no_components7 = 2000\n",
    "\n",
    "\n",
    "# With original features\n",
    "model.fit(x_train_cat_dog_reshape, y_train_cat_dog_f)\n",
    "\n",
    "\n",
    "# Test and visualise\n",
    "\n",
    "X_pred1 = model.predict(x_test_cat_dog_reshape)\n",
    "\n",
    "pd_results = pd.DataFrame([\n",
    "        ['No PCA', metrics.accuracy_score(y_test_cat_dog_f, X_pred1)],\n",
    "        [no_components1, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components1))],\n",
    "        [no_components2, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components2))],\n",
    "        [no_components3, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components3))],\n",
    "        [no_components4, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components4))],\n",
    "        [no_components5, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components5))],\n",
    "        [no_components6, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components6))],\n",
    "        [no_components7, metrics.accuracy_score(y_test_cat_dog_f, PCA_x_xt(no_components7))]\n",
    "    ], columns=['Number of PCA Components', 'Accuracy'])\n",
    "pd_results.plot(kind='barh', x='Number of PCA Components', y='Accuracy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Apply pca to original data\n",
    "\n",
    "x_train_reshape = x_train.reshape(x_train.shape[0],3*32*32)\n",
    "x_test_reshape = x_test.reshape(x_test.shape[0],3*32*32)\n",
    "\n",
    "y_train_f = y_train.flatten()\n",
    "y_test_f = y_test.flatten()\n",
    "\n",
    "# From the previous results, these 3 number of components showed the highest accuracies, therefore chosen\n",
    "no_components1 = 50\n",
    "no_components2 = 800\n",
    "no_components3 = 2000\n",
    "\n",
    "\n",
    "# 9 classifiers\n",
    "# 1 Naive Bayes Original\n",
    "NB_model = GaussianNB()\n",
    "\n",
    "# With original features\n",
    "NB_model.fit(x_train_reshape, y_train_f)\n",
    "\n",
    "# 3 Naive Bayes PCA\n",
    "def PCA_NB_x_xt_2(no_components):\n",
    "    start_time = time.time()\n",
    "    pca = PCA(n_components=no_components, svd_solver='randomized', whiten=True)\n",
    "    \n",
    "    x_pca_2d = pca.fit_transform(x_train_reshape)\n",
    "    xt_pca_2d = pca.transform(x_test_reshape)\n",
    "    \n",
    "    NB_model.fit(x_pca_2d, y_train_f)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    start_time2 = time.time()\n",
    "    X_pred_2 = NB_model.predict(xt_pca_2d)\n",
    "    end_time2 = time.time()\n",
    "    elapsed_time2 = end_time2 - start_time2\n",
    "    \n",
    "    return X_pred_2,elapsed_time,elapsed_time2\n",
    "\n",
    "# 1 Logistic Regression Original\n",
    "LR_model = LogisticRegression(max_iter=3, verbose=True)\n",
    "LR_model.fit(x_train_reshape,y_train_f)\n",
    "\n",
    "# 3 Logistic Regression PCA\n",
    "def PCA_LR_x_xt_2(no_components):\n",
    "    start_time = time.time()\n",
    "    pca = PCA(n_components=no_components, svd_solver='randomized', whiten=True)\n",
    "    \n",
    "    x_pca_2d = pca.fit_transform(x_train_reshape)\n",
    "    xt_pca_2d = pca.transform(x_test_reshape)\n",
    "    \n",
    "    LR_model.fit(x_pca_2d, y_train_f)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    \n",
    "    start_time2 = time.time()\n",
    "    X_pred_3 = LR_model.predict(xt_pca_2d)\n",
    "    end_time2 = time.time()\n",
    "    elapsed_time2 = end_time2 - start_time2\n",
    "    return X_pred_3,elapsed_time,elapsed_time2\n",
    "\n",
    "# CNN\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) #3: #input channels; 6: #output channels; 5: kernel size\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "max_epochs=2\n",
    "start_time_nn = time.time()\n",
    "for epoch in range(max_epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n",
    "end_time_nn = time.time()\n",
    "elapsed_time_nn_tr = end_time_nn - start_time_nn\n",
    "\n",
    "PATH = './cifar_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalaute the nine classifiers on the test set\n",
    "result1_pred, result1_tr_t, result1_t_t = PCA_NB_x_xt_2(no_components1)\n",
    "result2_pred, result2_tr_t, result2_t_t = PCA_NB_x_xt_2(no_components2)\n",
    "result3_pred, result3_tr_t, result3_t_t = PCA_NB_x_xt_2(no_components3)\n",
    "result4_pred, result4_tr_t, result4_t_t = PCA_LR_x_xt_2(no_components1)\n",
    "result5_pred, result5_tr_t, result5_t_t = PCA_LR_x_xt_2(no_components2)\n",
    "result6_pred, result6_tr_t, result6_t_t = PCA_LR_x_xt_2(no_components3)\n",
    "\n",
    "\n",
    "start_time_NB_tr = time.time()\n",
    "NB_model.fit(x_train_reshape, y_train_f)\n",
    "end_time_NB_tr = time.time()\n",
    "elasped_time_NB_tr = end_time_NB_tr - start_time_NB_tr\n",
    "\n",
    "\n",
    "start_time_NB_t = time.time()\n",
    "result0_pred = NB_model.predict(x_test_reshape)\n",
    "end_time_NB_t = time.time()\n",
    "elasped_time_NB_t = end_time_NB_t - start_time_NB_t\n",
    "\n",
    "\n",
    "\n",
    "start_time_LR_tr = time.time()\n",
    "LR_model.fit(x_train_reshape,y_train_f)\n",
    "end_time_LR_tr = time.time()\n",
    "elasped_time_LR_tr = end_time_LR_tr - start_time_LR_tr\n",
    "\n",
    "\n",
    "start_time_LR_t = time.time()\n",
    "result7_pred = LR_model.predict(x_test_reshape)\n",
    "end_time_LR_t = time.time()\n",
    "elasped_time_LR_t = end_time_LR_t - start_time_LR_t\n",
    "\n",
    "\n",
    "start_time_nn_t = time.time()\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  #testing phase, no need to compute the gradients to save time\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "end_time_nn_t = time.time()\n",
    "elapsed_time_nn_t = end_time_nn_t - start_time_nn_t\n",
    "\n",
    "accuracies = [metrics.accuracy_score(y_test_f, result0_pred),\n",
    "              metrics.accuracy_score(y_test_f, result1_pred),\n",
    "              metrics.accuracy_score(y_test_f, result2_pred),\n",
    "              metrics.accuracy_score(y_test_f, result3_pred),\n",
    "              metrics.accuracy_score(y_test_f, result7_pred),\n",
    "              metrics.accuracy_score(y_test_f, result4_pred),\n",
    "              metrics.accuracy_score(y_test_f, result5_pred),\n",
    "              metrics.accuracy_score(y_test_f, result6_pred),\n",
    "              correct / total]\n",
    "total_train_time = [elasped_time_NB_tr,result1_tr_t,result2_tr_t,result3_tr_t,\n",
    "                    elasped_time_NLR_tr,result4_tr_t,result5_tr_t,result6_tr_t,\n",
    "                    elapsed_time_nn_tr]\n",
    "total_test_time = [elasped_time_NB_t,result1_t_t,result2_t_t,result3_t_t,\n",
    "                   elasped_time_LR_t,result4_t_t,result5_t_t,result6_t_t,\n",
    "                   elapsed_time_nn_t]\n",
    "\n",
    "index = ['NB_Original', 'NB_PCA1', 'NB_PCA2','NB_PCA3',\n",
    "         'LR_Original', 'LR_PCA1', 'LR_PCA2','LR_PCA3',\n",
    "         'CNN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_time = [elasped_time_NB_tr,result1_tr_t,result2_tr_t,result3_tr_t,\n",
    "                    elasped_time_LR_tr,result4_tr_t,result5_tr_t,result6_tr_t,\n",
    "                    elapsed_time_nn_tr]\n",
    "total_test_time = [elasped_time_NB_t,result1_t_t,result2_t_t,result3_t_t,\n",
    "                   elasped_time_LR_t,result4_t_t,result5_t_t,result6_t_t,\n",
    "                   elapsed_time_nn_t]\n",
    "\n",
    "index = ['NB_Original', 'NB_PCA1', 'NB_PCA2','NB_PCA3',\n",
    "         'LR_Original', 'LR_PCA1', 'LR_PCA2','LR_PCA3',\n",
    "         'CNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'accuracies': accuracies}, index=index)\n",
    "df.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'total_train_time': total_train_time}, index=index)\n",
    "df.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'total_test_time':total_test_time}, index=index)\n",
    "df.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns; sns.set() # for statistical data visualization\n",
    "\n",
    "# for NB Original\n",
    "mat1 = confusion_matrix(y_test_f, NB_model.predict(x_test_reshape))\n",
    "# for NB PCA\n",
    "mat2 = confusion_matrix(y_test_f, PCA_NB_x_xt_2(no_components1)[0])\n",
    "mat3 = confusion_matrix(y_test_f, PCA_NB_x_xt_2(no_components2)[0])\n",
    "mat4 = confusion_matrix(y_test_f, PCA_NB_x_xt_2(no_components3)[0])\n",
    "# for LR Original\n",
    "mat5 = confusion_matrix(y_test_f, LR_model.predict(x_test_reshape))\n",
    "# for LR PCA\n",
    "mat6 = confusion_matrix(y_test_f, PCA_LR_x_xt_2(no_components1)[0])\n",
    "mat7 = confusion_matrix(y_test_f, PCA_LR_x_xt_2(no_components2)[0])\n",
    "mat8 = confusion_matrix(y_test_f, PCA_LR_x_xt_2(no_components3)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat1.T, square=True, annot=True, fmt='n', annot_kws={\"size\": 12})\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat2.T, square=True, annot=True, fmt='n', annot_kws={\"size\": 12})\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat3.T, square=True, annot=True, fmt='n', annot_kws={\"size\": 12})\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat4.T, square=True, annot=True, fmt='n', annot_kws={\"size\": 12})\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat5.T, square=True, annot=True, fmt='n', annot_kws={\"size\": 12})\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat6.T, square=True, annot=True, fmt='n', annot_kws={\"size\": 12})\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat7.T, square=True, annot=True, fmt='n', annot_kws={\"size\": 12})\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat8.T, square=True, annot=True, fmt='n', annot_kws={\"size\": 12})\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "# 1. For both with/without noise on train data, the result shows quite similarly. \n",
    "# Both results showed when k is 50, 800 and 2000 showed higher accuracy than without PCA.\n",
    "# 2. In Naive Bayes, bigger the k for PCA, longer training time and testing time. Number of k changes the results\n",
    "# of how similar each classes are, so the accuracy decreased.\n",
    "# 3. In Linear Regressio, it showed similar accuracies, however the difference came out whether PCA is applied or not.\n",
    "# Without PCA took even longer than with PCA in total training time. Nut once trained, barely no time consumed for testing\n",
    "# 4. CNN showed the best accuracy out of other classifers. However, it took quite a long training time and the longest testing time\n",
    "# out of all the classifiers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Denoising Autoencoder\n",
    "\n",
    "This uses both the original and noisy CIFAR-10 datasets (all 10 classes).\n",
    "\n",
    "Read about denoising autoencoder at [Wikepedia](https://en.wikipedia.org/wiki/Autoencoder#Denoising_autoencoder_(DAE)) and this [short introduction](https://towardsdatascience.com/denoising-autoencoders-explained-dbb82467fc2)\n",
    "\n",
    "Autoencoder architecture used so that it takes colour images as input (i.e., 3 input channels). \n",
    "\n",
    "**Training**: feed the **noisy training images** as input to the autoencoder; use a loss function that computes the reconstruction error between the **output of the autoencoder** and the respective **original images**.\n",
    "\n",
    "**Testing**: evaluate the autoencoder trained from above on the test datasets (feed noisy images in and compute reconstruction errors on original clean images. Find the **worstly denoised** 30 images (those with the largest reconstruction errors) in the test set and show them in pairs with the original images (60 images to show in total).\n",
    "\n",
    "At least two hyperparameters chosen to vary. Study **at least three different choices** for each hyperparameter. When varying one hyperparameter, all the other hyperparameters can be fixed. Visualise the performance sensitivity with respect to these hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoencoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + scale * torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "def normalize(data):\n",
    "    \"\"\"\n",
    "    Given a tensor containing 2 possible values, normalize this to 0/1\n",
    "\n",
    "    Args:\n",
    "        labels: a 1D tensor containing two possible scalar values\n",
    "    Returns:\n",
    "        A tensor normalize to 0/1 value\n",
    "    \"\"\"\n",
    "    max_val = torch.max(data)\n",
    "    min_val = torch.min(data)\n",
    "    norm_data = (data - min_val)/(max_val - min_val)\n",
    "\n",
    "    return norm_data\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "transform1 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    AddGaussianNoise(0., 1.)\n",
    "])\n",
    "\n",
    "# Download the data set\n",
    "original_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform1)\n",
    "\n",
    "original_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform1)\n",
    "\n",
    "# 1b. Put random noise, normalise will be done later using fuction above\n",
    "noised_trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                            download=True, transform=transform2)\n",
    "\n",
    "noised_testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                           download=True, transform=transform2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # 1 input image channel, 16 output channel, 3x3 square convolution\n",
    "            nn.Conv2d(3, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  #to range [0, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "myAE=Autoencoder()\n",
    "\n",
    "# Training noisy dataset\n",
    "\n",
    "#Hyperparameters for training\n",
    "batch_size=10\n",
    "learning_rate=0.05\n",
    "max_epochs = 2\n",
    "\n",
    "#Choose mean square error loss\n",
    "criterion = nn.MSELoss() \n",
    "#Choose the Adam optimiser\n",
    "optimizer = torch.optim.Adam(myAE.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "#Specify how the data will be loaded in batches (with random shffling)\n",
    "noised_train_loader = torch.utils.data.DataLoader(noised_trainset, batch_size=batch_size, shuffle=True)\n",
    "original_train_loader = torch.utils.data.DataLoader(original_trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "noised_testloader = torch.utils.data.DataLoader(noised_testset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "original_testloader = torch.utils.data.DataLoader(original_testset, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "\n",
    "#Storage\n",
    "outputs = []\n",
    "\n",
    "\n",
    "#Start training\n",
    "for epoch in range(max_epochs):\n",
    "    for data,data2 in zip(noised_train_loader,original_train_loader):\n",
    "        img, label = data\n",
    "        img2, label2 = data2\n",
    "        img = normalize(img)\n",
    "        img2= normalize(img2)\n",
    "        optimizer.zero_grad()\n",
    "        recon = myAE(img)\n",
    "        loss = criterion(recon, img2)\n",
    "        loss.backward()\n",
    "        optimizer.step()            \n",
    "    if (epoch % 3) == 0:\n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "    outputs.append((loss, img, recon),)\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "PATH = './cifar_myAE.pth'\n",
    "torch.save(myAE.state_dict(), PATH)\n",
    "\n",
    "myAE.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    for data,data2 in zip(noised_testloader,original_testloader):\n",
    "        img, label = data\n",
    "        img2, label2 = data2\n",
    "        img = normalize(img)\n",
    "        img2= normalize(img2)\n",
    "        optimizer.zero_grad()\n",
    "        recon = myAE(img)\n",
    "        loss = criterion(recon, img2)\n",
    "        loss.backward()\n",
    "        optimizer.step()            \n",
    "    if (epoch % 3) == 0:\n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "    outputs.append((loss, img, recon),)\n",
    "\n",
    "numImgs=30;\n",
    "for k in range(0, max_epochs, 9):\n",
    "    plt.figure(figsize=(numImgs, 2))\n",
    "    loss = outputs[k][0].detach().numpy()\n",
    "    imgs = outputs[k][1].detach().numpy() \n",
    "    recon = outputs[k][2].detach().numpy()\n",
    "    for i, item in enumerate(imgs):\n",
    "        if i >= numImgs: break\n",
    "        plt.subplot(2, numImgs, i+1)\n",
    "        plt.imshow(item[0])\n",
    "        \n",
    "    for i, item in enumerate(recon):\n",
    "        if i >= numImgs: break\n",
    "        plt.subplot(2, numImgs, numImgs+i+1)\n",
    "        plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Hyperparameters\n",
    "\n",
    "# 1\n",
    "#Hyperparameters for training\n",
    "batch_size=10\n",
    "learning_rate=0.005\n",
    "# max_epochs = 10\n",
    "\n",
    "optimizer = torch.optim.Adam(myAE.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "#Storage\n",
    "outputs = []\n",
    "\n",
    "#Start training\n",
    "for epoch in range(max_epochs):\n",
    "    for data,data2 in zip(noised_train_loader,original_train_loader):\n",
    "        img, label = data\n",
    "        img2, label2 = data2\n",
    "        img = normalize(img)\n",
    "        img2= normalize(img2)\n",
    "        optimizer.zero_grad()\n",
    "        recon = myAE(img)\n",
    "        loss = criterion(recon, img2)\n",
    "        loss.backward()\n",
    "        optimizer.step()            \n",
    "    if (epoch % 3) == 0:\n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "    outputs.append((epoch, img, recon),)\n",
    "    \n",
    "PATH = './cifar_myAE.pth'\n",
    "torch.save(myAE.state_dict(), PATH)\n",
    "\n",
    "myAE.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "#Hyperparameters for training\n",
    "batch_size=30\n",
    "learning_rate=0.005\n",
    "max_epochs = 15\n",
    "\n",
    "optimizer = torch.optim.Adam(myAE.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "#Storage\n",
    "outputs = []\n",
    "\n",
    "#Start training\n",
    "for epoch in range(max_epochs):\n",
    "    for data,data2 in zip(noised_train_loader,original_train_loader):\n",
    "        img, label = data\n",
    "        img2, label2 = data2\n",
    "        img = normalize(img)\n",
    "        img2= normalize(img2)\n",
    "        optimizer.zero_grad()\n",
    "        recon = myAE(img)\n",
    "        loss = criterion(recon, img2)\n",
    "        loss.backward()\n",
    "        optimizer.step()            \n",
    "    if (epoch % 3) == 0:\n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "    outputs.append((epoch, img, recon),)\n",
    "    \n",
    "PATH = './cifar_myAE.pth'\n",
    "torch.save(myAE.state_dict(), PATH)\n",
    "\n",
    "myAE.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3\n",
    "#Hyperparameters for training\n",
    "batch_size=10\n",
    "learning_rate=0.00005\n",
    "max_epochs = 20\n",
    "\n",
    "optimizer = torch.optim.Adam(myAE.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "#Storage\n",
    "outputs = []\n",
    "\n",
    "#Start training\n",
    "for epoch in range(max_epochs):\n",
    "    for data,data2 in zip(noised_train_loader,original_train_loader):\n",
    "        img, label = data\n",
    "        img2, label2 = data2\n",
    "        img = normalize(img)\n",
    "        img2= normalize(img2)\n",
    "        optimizer.zero_grad()\n",
    "        recon = myAE(img)\n",
    "        loss = criterion(recon, img2)\n",
    "        loss.backward()\n",
    "        optimizer.step()            \n",
    "    if (epoch % 3) == 0:\n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "    outputs.append((epoch, img, recon),)\n",
    "    \n",
    "PATH = './cifar_myAE.pth'\n",
    "torch.save(myAE.state_dict(), PATH)\n",
    "\n",
    "myAE.load_state_dict(torch.load(PATH))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observation\n",
    "# 1. Learning rate is the most important hyperparameter. If it's too small, it takes long training process and could get stuck\n",
    "#  but if it's to high, it may result in learning a sub-optimal set of weights too fast or an unstable training process.\n",
    "# 2. The balance between learning rate and the maximum number of epoches is important to find the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
